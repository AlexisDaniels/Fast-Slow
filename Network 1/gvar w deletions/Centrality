#BOOTSTRAPPING CENTRALITY

library("qgraph")
library("graphicalVAR")
library("psychonetrics")
library("NetworkComparisonTest")
library("bootnet")
library("networktools")
library("plyr")
names_all_1w <- c()




#### NETWORK 1 - WITH LOW OPTIMISM CONDITION
i <- 1
nodes_strength_1w <- c()
names_strength_1w <- matrix(0, 5, 1)
strength_list_1w <- matrix(0, 5, 1)

influence_step_one <- c()
influence_step_two <- c()
names_influence_step_one_1w <- matrix(0, 5, 1)
names_influence_step_two_1w <- matrix(0, 5, 1)
influence_step_one_list_1w <- matrix(0, 5, 1)
influence_step_two_list_1w <- matrix(0, 5, 1)



for (i in 1:100) {
  tryCatch({
    
beta1 <- getmatrix(mod1, "beta")

beta_low_1 <- beta1
beta_low_1[,5] <- beta_low_1[,5] * 0.5
beta_low_1[5,1:4] <- beta_low_1[5,1:4] * 0.5
beta_low_1 == beta1

# Simulate data with modifying 'mean' argument
low_sim_gvar_1 <- graphicalVARsim_MultiTime(15000, beta_low_1, kappa1, mean = c(0,0,0,0,0),
                                            var_slow = 5, time_slow = c(5))  #MultiTime simulation

#Delete repeated measurements
vector <- sort(c(seq(2,1500, 5), seq(3,1500, 5),
                 seq(4,1500, 5), seq(5,1500, 5)))
low_sim_gvar_1[vector, 5] <- NA

colnames(low_sim_gvar_1) <- xvars1


#NETWORK 1 - Negative connectivity (optimism -> down-suspic-lonely-anxious)
#### CONDITION 2 - Constantly low optimism ####

gvar1_w <- gvar(low_sim_gvar_1, vars = xvars1, estimator = "FIML", standardize = "z")
gvar1_w <- setoptimizer(gvar1_w, optimizer = "nlminb") # note Alexis: #This optimizer is dependent on OS
gvar1_w <- gvar1_w %>% runmodel

temporal_gvar1_w <- getmatrix(gvar1_w, "PDC")

temp_low_sim_gvar_1_w <- qgraph(temporal_gvar1_w, layout = true$layout, theme = "colorblind", 
                                directed = TRUE, diag = F, label.cex = 2, labels = labels_short1, 
                                title = "Sim from Network 3 w low Optimism",
                                vsize = 12, asize = 5, mar = rep(6,4), maximum = 0.263393)

temp_low_sim_gvar_1_w = as.igraph(temp_low_sim_gvar_1_w)

V(temp_low_sim_gvar_1_w)$name <- labels_short1
E(temp_low_sim_gvar_1_w)$weight <- abs(E(temp_low_sim_gvar_1_w)$weight)

#Strength
strength <- igraph::strength(temp_low_sim_gvar_1_w, mode = "all", loops = FALSE,
                               vids = V(temp_low_sim_gvar_1_w))
nodes_strength_1w <- (sort(strength, decreasing = TRUE))
names_strength_1w <- matrix(names(nodes_strength_1w),5,1)
strength_list_1w <- cbind(strength_list_1w, names_strength_1w)

#ExpectedInfluence (Step 1 & Step 2)
influence <- expectedInf(temp_low_sim_gvar_1_w, step = c("both", 1, 2), 
                                    directed = T)
influence_step_one <- as.matrix(influence[1])
influence_step_two <- as.matrix(influence[2])
influence_step_one <- influence_step_one[1,1]
influence_step_two <- influence_step_two[1,1]
influence_step_one <- influence_step_one$step1
influence_step_two <- influence_step_two$step2
influence_step_one <- influence_step_one %>% sort(decreasing = TRUE)
influence_step_two <- influence_step_two %>% sort(decreasing = TRUE)
names_influence_step_one_1w <- matrix(names(influence_step_one),5,1)
names_influence_step_two_1w <- matrix(names(influence_step_two),5,1)
influence_step_one_list_1w <- cbind(influence_step_one_list_1w, names_influence_step_one_1w)
influence_step_two_list_1w <- cbind(influence_step_two_list_1w, names_influence_step_two_1w)


#Closeness


}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
  
#  if (ncol(names_list_1w) > 100) { break()
#    }
}

a <- strength_list_1w
strength_list_1w <- strength_list_1w[,-1]
ncol(strength_list_1w)
#To count the number of times that "down" was most central, I need to provide it with a score
##e.g., 1st place = 5 points, 2nd place = 4 points, etc. (I think I need several if in a for)
#Or do I only count the ones that appeared most in 1st place, then 2nd place, etc?

strength_list_1w <- as.data.frame(strength_list_1w)

results_strength_1w <- rbind.fill(
data.frame(rbind(sort(table(unlist(strength_list_1w[1,])), decreasing=TRUE))),
data.frame(rbind(sort(table(unlist(strength_list_1w[2,])), decreasing=TRUE))),
data.frame(rbind(sort(table(unlist(strength_list_1w[3,])), decreasing=TRUE))),
data.frame(rbind(sort(table(unlist(strength_list_1w[4,])), decreasing=TRUE))),
data.frame(rbind(sort(table(unlist(strength_list_1w[5,])), decreasing=TRUE))))

#A value being the most central receives 5 points at each bootstrap. 2nd receives 4, and so on
results_strength_1w <- rbind(results_strength_1w, c(sum(results_strength_1w[,1] * c(5,4,3,2,1), na.rm = T),
                 sum(results_strength_1w[,2] * c(5,4,3,2,1), na.rm = T),
                 sum(results_strength_1w[,3] * c(5,4,3,2,1), na.rm = T),
                 sum(results_strength_1w[,4] * c(5,4,3,2,1), na.rm = T),
                 sum(results_strength_1w[,5] * c(5,4,3,2,1), na.rm = T)))
row.names(results_strength_1w) <- c('1st', '2nd', '3rd', '4th', '5th', 'sum_score')
results_strength_1w
#Apparently, the network is not really stable. Centrality changes A LOT.

#Now do the same for expectedInf

###Networktools tools
library(help = "networktools")
#goldbricker <- which nodes are redundant (i.e., they measure the same thing (colinear))
      #-> Another alternative is net_reduce, which removes the most redundant items
#impact - returns the global, structural or edge impact of each node
#plot.expectedInf
